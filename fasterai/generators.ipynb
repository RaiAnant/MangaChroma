{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generators.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaiAnant/MangaChroma/blob/master/fasterai/generators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKCNkMt_DHuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "cfa982a0-8b74-4125-cd47-37a85ca71097"
      },
      "source": [
        "!git clone https://github.com/RaiAnant/MangaChroma.git\n",
        "!pip install import_ipynb\n",
        "import import_ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MangaChroma'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/111)\u001b[K\rremote: Counting objects:   1% (2/111)\u001b[K\rremote: Counting objects:   2% (3/111)\u001b[K\rremote: Counting objects:   3% (4/111)\u001b[K\rremote: Counting objects:   4% (5/111)\u001b[K\rremote: Counting objects:   5% (6/111)\u001b[K\rremote: Counting objects:   6% (7/111)\u001b[K\rremote: Counting objects:   7% (8/111)\u001b[K\rremote: Counting objects:   8% (9/111)\u001b[K\rremote: Counting objects:   9% (10/111)\u001b[K\rremote: Counting objects:  10% (12/111)\u001b[K\rremote: Counting objects:  11% (13/111)\u001b[K\rremote: Counting objects:  12% (14/111)\u001b[K\rremote: Counting objects:  13% (15/111)\u001b[K\rremote: Counting objects:  14% (16/111)\u001b[K\rremote: Counting objects:  15% (17/111)\u001b[K\rremote: Counting objects:  16% (18/111)\u001b[K\rremote: Counting objects:  17% (19/111)\u001b[K\rremote: Counting objects:  18% (20/111)\u001b[K\rremote: Counting objects:  19% (22/111)\u001b[K\rremote: Counting objects:  20% (23/111)\u001b[K\rremote: Counting objects:  21% (24/111)\u001b[K\rremote: Counting objects:  22% (25/111)\u001b[K\rremote: Counting objects:  23% (26/111)\u001b[K\rremote: Counting objects:  24% (27/111)\u001b[K\rremote: Counting objects:  25% (28/111)\u001b[K\rremote: Counting objects:  26% (29/111)\u001b[K\rremote: Counting objects:  27% (30/111)\u001b[K\rremote: Counting objects:  28% (32/111)\u001b[K\rremote: Counting objects:  29% (33/111)\u001b[K\rremote: Counting objects:  30% (34/111)\u001b[K\rremote: Counting objects:  31% (35/111)\u001b[K\rremote: Counting objects:  32% (36/111)\u001b[K\rremote: Counting objects:  33% (37/111)\u001b[K\rremote: Counting objects:  34% (38/111)\u001b[K\rremote: Counting objects:  35% (39/111)\u001b[K\rremote: Counting objects:  36% (40/111)\u001b[K\rremote: Counting objects:  37% (42/111)\u001b[K\rremote: Counting objects:  38% (43/111)\u001b[K\rremote: Counting objects:  39% (44/111)\u001b[K\rremote: Counting objects:  40% (45/111)\u001b[K\rremote: Counting objects:  41% (46/111)\u001b[K\rremote: Counting objects:  42% (47/111)\u001b[K\rremote: Counting objects:  43% (48/111)\u001b[K\rremote: Counting objects:  44% (49/111)\u001b[K\rremote: Counting objects:  45% (50/111)\u001b[K\rremote: Counting objects:  46% (52/111)\u001b[K\rremote: Counting objects:  47% (53/111)\u001b[K\rremote: Counting objects:  48% (54/111)\u001b[K\rremote: Counting objects:  49% (55/111)\u001b[K\rremote: Counting objects:  50% (56/111)\u001b[K\rremote: Counting objects:  51% (57/111)\u001b[K\rremote: Counting objects:  52% (58/111)\u001b[K\rremote: Counting objects:  53% (59/111)\u001b[K\rremote: Counting objects:  54% (60/111)\u001b[K\rremote: Counting objects:  55% (62/111)\u001b[K\rremote: Counting objects:  56% (63/111)\u001b[K\rremote: Counting objects:  57% (64/111)\u001b[K\rremote: Counting objects:  58% (65/111)\u001b[K\rremote: Counting objects:  59% (66/111)\u001b[K\rremote: Counting objects:  60% (67/111)\u001b[K\rremote: Counting objects:  61% (68/111)\u001b[K\rremote: Counting objects:  62% (69/111)\u001b[K\rremote: Counting objects:  63% (70/111)\u001b[K\rremote: Counting objects:  64% (72/111)\u001b[K\rremote: Counting objects:  65% (73/111)\u001b[K\rremote: Counting objects:  66% (74/111)\u001b[K\rremote: Counting objects:  67% (75/111)\u001b[K\rremote: Counting objects:  68% (76/111)\u001b[K\rremote: Counting objects:  69% (77/111)\u001b[K\rremote: Counting objects:  70% (78/111)\u001b[K\rremote: Counting objects:  71% (79/111)\u001b[K\rremote: Counting objects:  72% (80/111)\u001b[K\rremote: Counting objects:  73% (82/111)\u001b[K\rremote: Counting objects:  74% (83/111)\u001b[K\rremote: Counting objects:  75% (84/111)\u001b[K\rremote: Counting objects:  76% (85/111)\u001b[K\rremote: Counting objects:  77% (86/111)\u001b[K\rremote: Counting objects:  78% (87/111)\u001b[K\rremote: Counting objects:  79% (88/111)\u001b[K\rremote: Counting objects:  80% (89/111)\u001b[K\rremote: Counting objects:  81% (90/111)\u001b[K\rremote: Counting objects:  82% (92/111)\u001b[K\rremote: Counting objects:  83% (93/111)\u001b[K\rremote: Counting objects:  84% (94/111)\u001b[K\rremote: Counting objects:  85% (95/111)\u001b[K\rremote: Counting objects:  86% (96/111)\u001b[K\rremote: Counting objects:  87% (97/111)\u001b[K\rremote: Counting objects:  88% (98/111)\u001b[K\rremote: Counting objects:  89% (99/111)\u001b[K\rremote: Counting objects:  90% (100/111)\u001b[K\rremote: Counting objects:  91% (102/111)\u001b[K\rremote: Counting objects:  92% (103/111)\u001b[K\rremote: Counting objects:  93% (104/111)\u001b[K\rremote: Counting objects:  94% (105/111)\u001b[K\rremote: Counting objects:  95% (106/111)\u001b[K\rremote: Counting objects:  96% (107/111)\u001b[K\rremote: Counting objects:  97% (108/111)\u001b[K\rremote: Counting objects:  98% (109/111)\u001b[K\rremote: Counting objects:  99% (110/111)\u001b[K\rremote: Counting objects: 100% (111/111)\u001b[K\rremote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/84)\u001b[K\rremote: Compressing objects:   2% (2/84)\u001b[K\rremote: Compressing objects:   3% (3/84)\u001b[K\rremote: Compressing objects:   4% (4/84)\u001b[K\rremote: Compressing objects:   5% (5/84)\u001b[K\rremote: Compressing objects:   7% (6/84)\u001b[K\rremote: Compressing objects:   8% (7/84)\u001b[K\rremote: Compressing objects:   9% (8/84)\u001b[K\rremote: Compressing objects:  10% (9/84)\u001b[K\rremote: Compressing objects:  11% (10/84)\u001b[K\rremote: Compressing objects:  13% (11/84)\u001b[K\rremote: Compressing objects:  14% (12/84)\u001b[K\rremote: Compressing objects:  15% (13/84)\u001b[K\rremote: Compressing objects:  16% (14/84)\u001b[K\rremote: Compressing objects:  17% (15/84)\u001b[K\rremote: Compressing objects:  19% (16/84)\u001b[K\rremote: Compressing objects:  20% (17/84)\u001b[K\rremote: Compressing objects:  21% (18/84)\u001b[K\rremote: Compressing objects:  22% (19/84)\u001b[K\rremote: Compressing objects:  23% (20/84)\u001b[K\rremote: Compressing objects:  25% (21/84)\u001b[K\rremote: Compressing objects:  26% (22/84)\u001b[K\rremote: Compressing objects:  27% (23/84)\u001b[K\rremote: Compressing objects:  28% (24/84)\u001b[K\rremote: Compressing objects:  29% (25/84)\u001b[K\rremote: Compressing objects:  30% (26/84)\u001b[K\rremote: Compressing objects:  32% (27/84)\u001b[K\rremote: Compressing objects:  33% (28/84)\u001b[K\rremote: Compressing objects:  34% (29/84)\u001b[K\rremote: Compressing objects:  35% (30/84)\u001b[K\rremote: Compressing objects:  36% (31/84)\u001b[K\rremote: Compressing objects:  38% (32/84)\u001b[K\rremote: Compressing objects:  39% (33/84)\u001b[K\rremote: Compressing objects:  40% (34/84)\u001b[K\rremote: Compressing objects:  41% (35/84)\u001b[K\rremote: Compressing objects:  42% (36/84)\u001b[K\rremote: Compressing objects:  44% (37/84)\u001b[K\rremote: Compressing objects:  45% (38/84)\u001b[K\rremote: Compressing objects:  46% (39/84)\u001b[K\rremote: Compressing objects:  47% (40/84)\u001b[K\rremote: Compressing objects:  48% (41/84)\u001b[K\rremote: Compressing objects:  50% (42/84)\u001b[K\rremote: Compressing objects:  51% (43/84)\u001b[K\rremote: Compressing objects:  52% (44/84)\u001b[K\rremote: Compressing objects:  53% (45/84)\u001b[K\rremote: Compressing objects:  54% (46/84)\u001b[K\rremote: Compressing objects:  55% (47/84)\u001b[K\rremote: Compressing objects:  57% (48/84)\u001b[K\rremote: Compressing objects:  58% (49/84)\u001b[K\rremote: Compressing objects:  59% (50/84)\u001b[K\rremote: Compressing objects:  60% (51/84)\u001b[K\rremote: Compressing objects:  61% (52/84)\u001b[K\rremote: Compressing objects:  63% (53/84)\u001b[K\rremote: Compressing objects:  64% (54/84)\u001b[K\rremote: Compressing objects:  65% (55/84)\u001b[K\rremote: Compressing objects:  66% (56/84)\u001b[K\rremote: Compressing objects:  67% (57/84)\u001b[K\rremote: Compressing objects:  69% (58/84)\u001b[K\rremote: Compressing objects:  70% (59/84)\u001b[K\rremote: Compressing objects:  71% (60/84)\u001b[K\rremote: Compressing objects:  72% (61/84)\u001b[K\rremote: Compressing objects:  73% (62/84)\u001b[K\rremote: Compressing objects:  75% (63/84)\u001b[K\rremote: Compressing objects:  76% (64/84)\u001b[K\rremote: Compressing objects:  77% (65/84)\u001b[K\rremote: Compressing objects:  78% (66/84)\u001b[K\rremote: Compressing objects:  79% (67/84)\u001b[K\rremote: Compressing objects:  80% (68/84)\u001b[K\rremote: Compressing objects:  82% (69/84)\u001b[K\rremote: Compressing objects:  83% (70/84)\u001b[K\rremote: Compressing objects:  84% (71/84)\u001b[K\rremote: Compressing objects:  85% (72/84)\u001b[K\rremote: Compressing objects:  86% (73/84)\u001b[K\rremote: Compressing objects:  88% (74/84)\u001b[K\rremote: Compressing objects:  89% (75/84)\u001b[K\rremote: Compressing objects:  90% (76/84)\u001b[K\rremote: Compressing objects:  91% (77/84)\u001b[K\rremote: Compressing objects:  92% (78/84)\u001b[K\rremote: Compressing objects:  94% (79/84)\u001b[K\rremote: Compressing objects:  95% (80/84)\u001b[K\rremote: Compressing objects:  96% (81/84)\u001b[K\rremote: Compressing objects:  97% (82/84)\u001b[K\rremote: Compressing objects:  98% (83/84)\u001b[K\rremote: Compressing objects: 100% (84/84)\u001b[K\rremote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "Receiving objects:   0% (1/111)   \rReceiving objects:   1% (2/111)   \rReceiving objects:   2% (3/111)   \rReceiving objects:   3% (4/111)   \rReceiving objects:   4% (5/111)   \rReceiving objects:   5% (6/111)   \rReceiving objects:   6% (7/111)   \rReceiving objects:   7% (8/111)   \rReceiving objects:   8% (9/111)   \rReceiving objects:   9% (10/111)   \rReceiving objects:  10% (12/111)   \rReceiving objects:  11% (13/111)   \rReceiving objects:  12% (14/111)   \rReceiving objects:  13% (15/111)   \rReceiving objects:  14% (16/111)   \rReceiving objects:  15% (17/111)   \rReceiving objects:  16% (18/111)   \rReceiving objects:  17% (19/111)   \rReceiving objects:  18% (20/111)   \rReceiving objects:  19% (22/111)   \rReceiving objects:  20% (23/111)   \rReceiving objects:  21% (24/111)   \rReceiving objects:  22% (25/111)   \rReceiving objects:  23% (26/111)   \rReceiving objects:  24% (27/111)   \rReceiving objects:  25% (28/111)   \rReceiving objects:  26% (29/111)   \rReceiving objects:  27% (30/111)   \rReceiving objects:  28% (32/111)   \rReceiving objects:  29% (33/111)   \rReceiving objects:  30% (34/111)   \rReceiving objects:  31% (35/111)   \rReceiving objects:  32% (36/111)   \rReceiving objects:  33% (37/111)   \rremote: Total 111 (delta 44), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects:  34% (38/111)   \rReceiving objects:  35% (39/111)   \rReceiving objects:  36% (40/111)   \rReceiving objects:  37% (42/111)   \rReceiving objects:  38% (43/111)   \rReceiving objects:  39% (44/111)   \rReceiving objects:  40% (45/111)   \rReceiving objects:  41% (46/111)   \rReceiving objects:  42% (47/111)   \rReceiving objects:  43% (48/111)   \rReceiving objects:  44% (49/111)   \rReceiving objects:  45% (50/111)   \rReceiving objects:  46% (52/111)   \rReceiving objects:  47% (53/111)   \rReceiving objects:  48% (54/111)   \rReceiving objects:  49% (55/111)   \rReceiving objects:  50% (56/111)   \rReceiving objects:  51% (57/111)   \rReceiving objects:  52% (58/111)   \rReceiving objects:  53% (59/111)   \rReceiving objects:  54% (60/111)   \rReceiving objects:  55% (62/111)   \rReceiving objects:  56% (63/111)   \rReceiving objects:  57% (64/111)   \rReceiving objects:  58% (65/111)   \rReceiving objects:  59% (66/111)   \rReceiving objects:  60% (67/111)   \rReceiving objects:  61% (68/111)   \rReceiving objects:  62% (69/111)   \rReceiving objects:  63% (70/111)   \rReceiving objects:  64% (72/111)   \rReceiving objects:  65% (73/111)   \rReceiving objects:  66% (74/111)   \rReceiving objects:  67% (75/111)   \rReceiving objects:  68% (76/111)   \rReceiving objects:  69% (77/111)   \rReceiving objects:  70% (78/111)   \rReceiving objects:  71% (79/111)   \rReceiving objects:  72% (80/111)   \rReceiving objects:  73% (82/111)   \rReceiving objects:  74% (83/111)   \rReceiving objects:  75% (84/111)   \rReceiving objects:  76% (85/111)   \rReceiving objects:  77% (86/111)   \rReceiving objects:  78% (87/111)   \rReceiving objects:  79% (88/111)   \rReceiving objects:  80% (89/111)   \rReceiving objects:  81% (90/111)   \rReceiving objects:  82% (92/111)   \rReceiving objects:  83% (93/111)   \rReceiving objects:  84% (94/111)   \rReceiving objects:  85% (95/111)   \rReceiving objects:  86% (96/111)   \rReceiving objects:  87% (97/111)   \rReceiving objects:  88% (98/111)   \rReceiving objects:  89% (99/111)   \rReceiving objects:  90% (100/111)   \rReceiving objects:  91% (102/111)   \rReceiving objects:  92% (103/111)   \rReceiving objects:  93% (104/111)   \rReceiving objects:  94% (105/111)   \rReceiving objects:  95% (106/111)   \rReceiving objects:  96% (107/111)   \rReceiving objects:  97% (108/111)   \rReceiving objects:  98% (109/111)   \rReceiving objects:  99% (110/111)   \rReceiving objects: 100% (111/111)   \rReceiving objects: 100% (111/111), 25.68 KiB | 410.00 KiB/s, done.\n",
            "Resolving deltas:   0% (0/44)   \rResolving deltas:   4% (2/44)   \rResolving deltas:  61% (27/44)   \rResolving deltas:  68% (30/44)   \rResolving deltas:  72% (32/44)   \rResolving deltas:  79% (35/44)   \rResolving deltas: 100% (44/44)   \rResolving deltas: 100% (44/44), done.\n",
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=a83259b81f3335de56534f129af531fe0bf397aca74b9a5c0f8433672a847246\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0pIUbw450h",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jE6P4Mj48ud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "50c3d370-1094-4042-dac0-fd4f33a18c07"
      },
      "source": [
        "from fastai.vision import *\n",
        "from fastai.vision.learner import cnn_config\n",
        "from MangaChroma.fasterai.unet import DynamicUnetWide, DynamicUnetDeep\n",
        "from MangaChroma.fasterai.loss import FeatureLoss\n",
        "# from MangaChroma.fasterai.dataset import *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from /content/MangaChroma/fasterai/unet.ipynb\n",
            "fatal: destination path 'MangaChroma' already exists and is not an empty directory.\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
            "importing Jupyter notebook from /content/MangaChroma/fasterai/layers.ipynb\n",
            "importing Jupyter notebook from /content/MangaChroma/fasterai/loss.ipynb\n",
            "Sun Aug 18 15:04:38 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    26W / 149W |     11MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q1pLMht5ady",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For getting the model prepared at inference time\n",
        "def gen_inference_wide(root_folder:Path, wights_name:str, nf_factor:int=2, arch=models.resnet101)->Learner:\n",
        "  data = get_dummy_databunch()\n",
        "  learn = gen_learner_wide(data=data, gen_loss=F1.l1_loss, nf_factor=nf_factor, arch=arch)\n",
        "  learn.path = root_folder\n",
        "  learn.load(weights_name)\n",
        "  learn.model.eval()\n",
        "  return learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugy9Ru8Z7v5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unet_learner_wide(data:DataBunch, arch:Callable, pretrained:bool=True, blur_final:bool=True,\n",
        "                      norm_type:Optional[NormType]=NormType, split_on:Optional[SplitFuncOrIdxList]=None,\n",
        "                      blur:bool=False, self_attention:bool=False, y_range:Optional[Tuple[float,float]]=None, last_cross:bool=True,\n",
        "                      bottle:bool=False, nf_factor:int=1, **kwargs:Any)->Learner:\n",
        "  \"\"\"Build Unet learner from `data` and `arch`.\"\"\"\n",
        "  #Get the metadata associated with `arch`.\n",
        "  meta = cnn_config(arch)\n",
        "  body = create_body(arch, pretrained)    \n",
        "  model = to_device(DynamicUnetWide(body, n_classes=data.c, blur=blur, blur_final=blur_final,\n",
        "                    self_attention=self_attention, y_range=y_range, norm_type=norm_type, last_cross=last_cross,\n",
        "                    bottle=bottle, nf_factor=nf_factor), data.device)\n",
        "  learn = Learner(data, model, **kwargs)\n",
        "  learn.split(ifnone(split_on,meta['split']))\n",
        "  if pretrained: learn.freeze()\n",
        "  apply_init(model[2], nn.init.kaiming_normal_)\n",
        "  return learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3w6WuXi7iVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_learner_wide(data:ImageDataBunch, gen_loss=FeatureLoss(), arch=models.resnet101, nf_factor:int=2)->Learner:\n",
        "  return unet_learner_wide(data, arch=arch, wd=1e-3, blur=True, norm_type=NormType.Spectral, \n",
        "                           self_attention=True, y_range=(-3.,3.), loss_func=gen_loss, nf_factor=nf_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfF1tk7BEz3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_inference_deep(root_folder:Path, weights_name:str, arch=models.resnet34, nf_factor:float=1.5)->Learner:\n",
        "  data = get_dummy_databunch()\n",
        "  learn = gen_learner_deep(data=data, gen_loss=F.l1_loss, arch=arch, nf_factor=nf_factor)\n",
        "  learn.path = root_folder\n",
        "  learn.load(weights_name)\n",
        "  learn.model.eval()\n",
        "  return learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxeNUB_3E2B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unet_learner_deep(data:DataBunch, arch:Callable, pretrained:bool=True, blur_final:bool=True,\n",
        "                 norm_type:Optional[NormType]=NormType, split_on:Optional[SplitFuncOrIdxList]=None, \n",
        "                 blur:bool=False, self_attention:bool=False, y_range:Optional[Tuple[float,float]]=None, last_cross:bool=True,\n",
        "                 bottle:bool=False, nf_factor:float=1.5, **kwargs:Any)->Learner:\n",
        "  \"Build Unet learner from `data` and `arch`.\"\n",
        "  meta = cnn_config(arch)\n",
        "  body = create_body(arch, pretrained)\n",
        "  model = to_device(DynamicUnetDeep(body, n_classes=data.c, blur=blur, blur_final=blur_final,\n",
        "        self_attention=self_attention, y_range=y_range, norm_type=norm_type, last_cross=last_cross,\n",
        "        bottle=bottle, nf_factor=nf_factor), data.device)\n",
        "  learn = Learner(data, model, **kwargs)\n",
        "  learn.split(ifnone(split_on,meta['split']))\n",
        "  if pretrained: learn.freeze()\n",
        "  apply_init(model[2], nn.init.kaiming_normal_)\n",
        "  return learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61czbCHj-Ggs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_learner_deep(data:ImageDataBunch, gen_loss=FeatureLoss(), arch=models.resnet34, nf_factor:float=1.5)->Learner:\n",
        "  return unet_learner_deep(data, arch, wd=1e-3, blur=True, norm_type=NormType.Spectral,\n",
        "                      self_attention=True, y_range=(-3.,3.), loss_func=gen_loss, nf_factor=nf_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24zGNrUhEnpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}