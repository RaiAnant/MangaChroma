{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visualize.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaiAnant/MangaChroma/blob/master/fasterai/visualize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5bnhpRaCR8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.core import *\n",
        "from fastai.vision import *\n",
        "from matplotlib.axes import Axes\n",
        "from matplotlib.figure import Figure\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from .filters import IFilter, MasterFilter, ColorizerFilter\n",
        "from .generators import gen_inference_deep, gen_inference_wide\n",
        "from tensorboardX import SummaryWriter\n",
        "from scipy import misc\n",
        "from PIL import Image \n",
        "import ffmpeg\n",
        "import youtube_dl\n",
        "import gc\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import base64\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n",
        "from IPython.display import Image as ipythonimage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfwpU8AHCYcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelImageVisualizer():\n",
        "    def __init__(self, filter:IFilter, results_dir:str=None):\n",
        "        self.filter = filter\n",
        "        self.results_dir=None if results_dir is None else Path(results_dir)\n",
        "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    def _clean_mem(self):\n",
        "        torch.cuda.empty_cache()\n",
        "        #gc.collect()\n",
        "\n",
        "    def _open_pil_image(self, path:Path)->Image:\n",
        "        return PIL.Image.open(path).convert('RGB')\n",
        "\n",
        "    def _get_image_from_url(self, url:str)->Image:\n",
        "        response = requests.get(url)\n",
        "        img = PIL.Image.open(BytesIO(response.content)).convert('RGB')\n",
        "        return img\n",
        "\n",
        "    def plot_transformed_image_from_url(self, url:str, path:str='test_images/image.png', figsize:(int,int)=(20,20), \n",
        "            render_factor:int=None, display_render_factor:bool=False, compare:bool=False)->Path:\n",
        "        img = self._get_image_from_url(url)\n",
        "        img.save(path)\n",
        "        return self.plot_transformed_image(path=path, figsize=figsize, render_factor=render_factor, \n",
        "                                            display_render_factor=display_render_factor, compare=compare)\n",
        "\n",
        "    def plot_transformed_image(self, path:str, figsize:(int,int)=(20,20), render_factor:int=None, \n",
        "                            display_render_factor:bool=False, compare:bool=False)->Path:\n",
        "        path = Path(path)\n",
        "        result = self.get_transformed_image(path, render_factor)\n",
        "        orig = self._open_pil_image(path)\n",
        "        if compare: \n",
        "            self._plot_comparison(figsize, render_factor, display_render_factor, orig, result)\n",
        "        else:\n",
        "            self._plot_solo(figsize, render_factor, display_render_factor, result)\n",
        "\n",
        "        return self._save_result_image(path, result)\n",
        "\n",
        "    def _plot_comparison(self, figsize:(int,int), render_factor:int, display_render_factor:bool, orig:Image, result:Image):\n",
        "        fig,axes = plt.subplots(1, 2, figsize=figsize)\n",
        "        self._plot_image(orig, axes=axes[0], figsize=figsize, render_factor=render_factor, display_render_factor=False)\n",
        "        self._plot_image(result, axes=axes[1], figsize=figsize, render_factor=render_factor, display_render_factor=display_render_factor)\n",
        " \n",
        "    def _plot_solo(self, figsize:(int,int), render_factor:int, display_render_factor:bool, result:Image):\n",
        "        fig,axes = plt.subplots(1, 1, figsize=figsize)\n",
        "        self._plot_image(result, axes=axes, figsize=figsize, render_factor=render_factor, display_render_factor=display_render_factor)\n",
        "\n",
        "    def _save_result_image(self, source_path:Path, image:Image)->Path:\n",
        "        result_path = self.results_dir/source_path.name\n",
        "        image.save(result_path)\n",
        "        return result_path\n",
        "\n",
        "    def get_transformed_image(self, path:Path, render_factor:int=None)->Image:\n",
        "        self._clean_mem()\n",
        "        orig_image = self._open_pil_image(path)\n",
        "        filtered_image = self.filter.filter(orig_image, orig_image, render_factor=render_factor)\n",
        "        return filtered_image\n",
        "\n",
        "    def _plot_image(self, image:Image, render_factor:int, axes:Axes=None, figsize=(20,20), display_render_factor:bool=False):\n",
        "        if axes is None: \n",
        "            _,axes = plt.subplots(figsize=figsize)\n",
        "        axes.imshow(np.asarray(image)/255)\n",
        "        axes.axis('off')\n",
        "        if render_factor is not None and display_render_factor:\n",
        "            plt.text(10,10,'render_factor: ' + str(render_factor), color='white', backgroundcolor='black')\n",
        "\n",
        "    def _get_num_rows_columns(self, num_images:int, max_columns:int)->(int,int):\n",
        "        columns = min(num_images, max_columns)\n",
        "        rows = num_images//columns\n",
        "        rows = rows if rows * columns == num_images else rows + 1\n",
        "        return rows, columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90wSSccdCeb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VideoColorizer():\n",
        "    def __init__(self, vis:ModelImageVisualizer):\n",
        "        self.vis=vis\n",
        "        workfolder = Path('./video')\n",
        "        self.source_folder = workfolder/\"source\"\n",
        "        self.bwframes_root = workfolder/\"bwframes\"\n",
        "        self.audio_root = workfolder/\"audio\"\n",
        "        self.colorframes_root = workfolder/\"colorframes\"\n",
        "        self.result_folder = workfolder/\"result\"\n",
        "\n",
        "    def _purge_images(self, dir):\n",
        "        for f in os.listdir(dir):\n",
        "            if re.search('.*?\\.jpg', f):\n",
        "                os.remove(os.path.join(dir, f))\n",
        "\n",
        "    def _get_fps(self, source_path: Path)->str:\n",
        "        probe = ffmpeg.probe(str(source_path))\n",
        "        stream_data = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
        "        return stream_data['avg_frame_rate']\n",
        "\n",
        "    def _download_video_from_url(self, source_url, source_path:Path):\n",
        "        if source_path.exists(): source_path.unlink()\n",
        "\n",
        "        ydl_opts = {    \n",
        "            'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',     \n",
        "            'outtmpl': str(source_path)   \n",
        "            }\n",
        "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "          \n",
        "            ydl.download([source_url])\n",
        "\n",
        "    def _extract_raw_frames(self, source_path:Path):\n",
        "        bwframes_folder = self.bwframes_root/(source_path.stem)\n",
        "        bwframe_path_template = str(bwframes_folder/'%5d.jpg')\n",
        "        bwframes_folder.mkdir(parents=True, exist_ok=True)\n",
        "        self._purge_images(bwframes_folder)\n",
        "        ffmpeg.input(str(source_path)).output(str(bwframe_path_template), format='image2', vcodec='mjpeg', qscale=0).run(capture_stdout=True)\n",
        "\n",
        "\n",
        "    def _colorize_raw_frames(self, source_path:Path, render_factor:int=None):\n",
        "        colorframes_folder = self.colorframes_root/(source_path.stem)\n",
        "        colorframes_folder.mkdir(parents=True, exist_ok=True)\n",
        "        self._purge_images(colorframes_folder)\n",
        "        bwframes_folder = self.bwframes_root/(source_path.stem)\n",
        "\n",
        "        for img in progress_bar(os.listdir(str(bwframes_folder))):\n",
        "            img_path = bwframes_folder/img\n",
        "            if os.path.isfile(str(img_path)):\n",
        "                color_image = self.vis.get_transformed_image(str(img_path), render_factor=render_factor)\n",
        "                color_image.save(str(colorframes_folder/img))\n",
        "    \n",
        "    def _build_video(self, source_path:Path)->Path:\n",
        "        colorized_path = self.result_folder/(source_path.name.replace('.mp4', '_no_audio.mp4'))\n",
        "        colorframes_folder = self.colorframes_root/(source_path.stem)\n",
        "        colorframes_path_template = str(colorframes_folder/'%5d.jpg')\n",
        "        colorized_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        if colorized_path.exists(): colorized_path.unlink()\n",
        "        fps = self._get_fps(source_path)\n",
        "\n",
        "        ffmpeg.input(str(colorframes_path_template), format='image2', vcodec='mjpeg', framerate=fps) \\\n",
        "            .output(str(colorized_path), crf=17, vcodec='libx264') \\\n",
        "            .run(capture_stdout=True)\n",
        "\n",
        "        result_path = self.result_folder/source_path.name\n",
        "        if result_path.exists(): result_path.unlink()\n",
        "        #making copy of non-audio version in case adding back audio doesn't apply or fails.\n",
        "        shutil.copyfile(str(colorized_path), str(result_path))\n",
        "\n",
        "        # adding back sound here\n",
        "        audio_file = Path(str(source_path).replace('.mp4', '.aac'))\n",
        "        if audio_file.exists(): audio_file.unlink()\n",
        "\n",
        "        os.system('ffmpeg -y -i \"' + str(source_path) + '\" -vn -acodec copy \"' + str(audio_file) + '\"')\n",
        "\n",
        "        if audio_file.exists:\n",
        "            os.system('ffmpeg -y -i \"' + str(colorized_path) + '\" -i \"' + str(audio_file) \n",
        "                + '\" -shortest -c:v copy -c:a aac -b:a 256k \"' + str(result_path) + '\"')\n",
        "        print('Video created here: ' + str(result_path))\n",
        "        return result_path\n",
        "\n",
        "    def colorize_from_url(self, source_url, file_name:str, render_factor:int=None)->Path: \n",
        "        source_path =  self.source_folder/file_name\n",
        "        self._download_video_from_url(source_url, source_path)\n",
        "        return self._colorize_from_path(source_path, render_factor=render_factor)\n",
        "\n",
        "    def colorize_from_file_name(self, file_name:str, render_factor:int=None)->Path:\n",
        "        source_path =  self.source_folder/file_name\n",
        "        return self._colorize_from_path(source_path, render_factor=render_factor)\n",
        "\n",
        "    def _colorize_from_path(self, source_path:Path, render_factor:int=None)->Path:\n",
        "        if not source_path.exists():\n",
        "            raise Exception('Video at path specfied, ' + str(source_path) + ' could not be found.')\n",
        "\n",
        "        self._extract_raw_frames(source_path)\n",
        "        self._colorize_raw_frames(source_path, render_factor=render_factor)\n",
        "        return self._build_video(source_path)\n",
        "\n",
        "\n",
        "def get_video_colorizer(render_factor:int=21)->VideoColorizer:\n",
        "    return get_stable_video_colorizer(render_factor=render_factor)\n",
        "\n",
        "def get_stable_video_colorizer(root_folder:Path=Path('./'), weights_name:str='ColorizeVideo_gen', \n",
        "        results_dir='result_images', render_factor:int=21)->VideoColorizer:\n",
        "    learn = gen_inference_wide(root_folder=root_folder, weights_name=weights_name)\n",
        "    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n",
        "    vis = ModelImageVisualizer(filtr, results_dir=results_dir)\n",
        "    return VideoColorizer(vis)\n",
        "\n",
        "def get_image_colorizer(render_factor:int=35, artistic:bool=True)->ModelImageVisualizer:\n",
        "    if artistic:\n",
        "        return get_artistic_image_colorizer(render_factor=render_factor)\n",
        "    else:\n",
        "        return get_stable_image_colorizer(render_factor=render_factor)\n",
        "\n",
        "def get_stable_image_colorizer(root_folder:Path=Path('./'), weights_name:str='ColorizeStable_gen', \n",
        "        results_dir='result_images', render_factor:int=35)->ModelImageVisualizer:\n",
        "    learn = gen_inference_wide(root_folder=root_folder, weights_name=weights_name)\n",
        "    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n",
        "    vis = ModelImageVisualizer(filtr, results_dir=results_dir)\n",
        "    return vis\n",
        "\n",
        "def get_artistic_image_colorizer(root_folder:Path=Path('./'), weights_name:str='ColorizeArtistic_gen', \n",
        "        results_dir='result_images', render_factor:int=35)->ModelImageVisualizer:\n",
        "    learn = gen_inference_deep(root_folder=root_folder, weights_name=weights_name)\n",
        "    filtr = MasterFilter([ColorizerFilter(learn=learn)], render_factor=render_factor)\n",
        "    vis = ModelImageVisualizer(filtr, results_dir=results_dir)\n",
        "    return vis\n",
        "\n",
        "def show_image_in_notebook(image_path:Path):\n",
        "    ipythondisplay.display(ipythonimage(str(image_path)))\n",
        "\n",
        "def show_video_in_notebook(video_path:Path):\n",
        "    video = io.open(video_path, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}