{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "filters.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaiAnant/MangaChroma/blob/master/fasterai/filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWsEY6JftJtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "fc93a30c-2315-4e5a-ecd4-e1d3fde2804d"
      },
      "source": [
        "!git clone https://github.com/RaiAnant/MangaChroma.git\n",
        "!pip install import_ipynb\n",
        "import import_ipynb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MangaChroma'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 83 (delta 32), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n",
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=891fca376a6f9bd2675006ab6c08bcdca61710adccb58fa046ed09c49d4a333f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AGe67nKsLIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import ndarray\n",
        "from abc import ABC, abstractmethod\n",
        "from MangaChroma.fasterai.critics import colorize_crit_learner\n",
        "from fastai.core import *\n",
        "from fastai.vision import *\n",
        "from fastai.vision.image import *\n",
        "from fastai.vision.data import *\n",
        "from fastai import *\n",
        "import math\n",
        "from scipy import misc\n",
        "import cv2\n",
        "from PIL import Image as PilImage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUE9-j3nsxLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Abstract class for all the subsequent filter classes\n",
        "class IFilter(ABC):\n",
        "  @abstractmethod\n",
        "  def filter(self, orig_image:PilImage, filtered_image:PilImage, render_factor:int)->PilImage:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Earyk1jvG39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ??normalize_funcs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuUPWtUXvQ64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ??denormalize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diqC_wgwus9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseFilter(IFilter):\n",
        "  def __init__(self, learn:Learner):\n",
        "    supter().__init__()\n",
        "    self.learn = learn\n",
        "    self.norm, self.denorm = normalize_funcs(*imagenet_stats)\n",
        "\n",
        "  def _transform(self, image:PilImage)->PilImage:\n",
        "    return image\n",
        "\n",
        "  def _scale_to_square(self, orig:PilImage, targ:int)->PilImage:\n",
        "    #a simple stretch to fit a square really makes a big difference in rendering quality/consistency.\n",
        "    targ_sz = (targ, targ)\n",
        "    return orig.resize(targ_sz, resample=PIL.Image.BILINEAR) \n",
        "\n",
        "  def  _get_model_ready_img(self, orig:PilImage, sz:int)->PilImage:\n",
        "    result = self._scale_to_square(orig, sz)\n",
        "    result = self._transform(result)\n",
        "    return result\n",
        "\n",
        "  def _model_process(Self, orig:PilImage, sz:int)->PilImage:\n",
        "    model_image = self._get_model_ready_img(orig, sz)\n",
        "    x = pil2tensor(model_image, np.float32)\n",
        "    x.div_(255)\n",
        "    x, y = self.norm((x,x), do_x=True)\n",
        "    ## ??\n",
        "    result = self.learn.pred_batch(ds_type=DatasetType.Valid, \n",
        "        batch=(x[None].cuda(),y[None]), reconstruct=True)\n",
        "    out = result[0]\n",
        "    out = self.denorm(out.px, do_x=False)\n",
        "    out = image2np(out*255).astype(np.uint8)\n",
        "    return PilImage.fromarray(out)\n",
        "\n",
        "  def _unsquare(self, image:PilImage, orig:PilImage)->PilImage:\n",
        "    targ_sz = orig.size\n",
        "    image = image.resize(targ_sz, resample=PIL.Image.BILINEAR)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pj9Qkrm1qJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ColorizerFilter(BaseFilter):\n",
        "  def __init__(self, learn:Learner, map_to_orig:bool=True):\n",
        "    super().__init__(learn=learn)\n",
        "    self.render_base=16\n",
        "    self.map_to_orig=map_to_orig\n",
        "\n",
        "  def filter(self, orig_image:PilImage, filtered_image:PilImage, render_factor:int)->PilImage:\n",
        "    render_sz = render_factor * self.render_base\n",
        "    model_image = self._model_process(orig=filtered_image, sz=render_sz)\n",
        "\n",
        "    if self.map_to_orig:\n",
        "      return self._post_process(model_image, orig_image)\n",
        "    else:\n",
        "      return self._post_process(model_image, filtered_image)\n",
        "\n",
        "  def  _transform(self, image:PilImage)->PilImage:\n",
        "    return image.convert('LA').convert('RGB')\n",
        "\n",
        "  #This takes advantage of the fact that human eyes are much less sensitive to \n",
        "  #imperfections in chrominance compared to luminance.  This means we can\n",
        "  #save a lot on memory and processing in the model, yet get a great high\n",
        "  #resolution result at the end.  This is primarily intended just for \n",
        "  #inference\n",
        "  def _post_process(self, raw_color:PilImage, orig:PilImage)->PilImage:\n",
        "    raw_color = self._unsquare(raw_color, orig)\n",
        "    color_np = np.asarray(raw_color)\n",
        "    orig_np = np.asarray(orig)\n",
        "    color_yuv = cv2.cvtColor(color_np, cv2.COLOR_BGR2YUV)\n",
        "    #do a black and white transform first to get better luminance values\n",
        "    orig_yuv = cv2.cvtColor(orig_np, cv2.COLOR_BGR2YUV)\n",
        "    hires = np.copy(orig_yuv)\n",
        "    hires[:,:,1:3] = color_yuv[:,:,1:3]\n",
        "    final = cv2.cvtColor(hires, cv2.COLOR_YUV2BGR)  \n",
        "    final = PilImage.fromarray(final) \n",
        "    return final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghx2tCHT5J42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MasterFilter(BaseFilter):\n",
        "  def __init__(self, filters:[IFilter], render_factor:int):\n",
        "    self.filters=filters\n",
        "    self.render_factor=render_factor\n",
        "\n",
        "  def filter(self, orig_image:PilImage, filtered_image:PilImage, render_factor:int=None)->PilImage:\n",
        "    render_factor = self.render_factor if render_factor is None else render_factor\n",
        "\n",
        "    for filter in self.filters:\n",
        "      filtered_image=filter.filter(orig_image, filtered_image, render_factor)\n",
        "    \n",
        "    return filtered_image"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}