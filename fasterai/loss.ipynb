{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "loss.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaiAnant/MangaChroma/blob/master/fasterai/loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD9vMOuSObGP",
        "colab_type": "code",
        "outputId": "9864c0ee-9f25-478c-b2ab-6973aa66caba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 16 11:51:44 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    17W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS4YkVKJQMXB",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsaNJFaNQPzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.core import *\n",
        "from fastai.torch_core import *\n",
        "from fastai.callbacks  import hook_outputs\n",
        "import torchvision.models as models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRTIBklQQTVu",
        "colab_type": "text"
      },
      "source": [
        "## Loss classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FIYV8F4SvDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# m = models.vgg16_bn(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ASWCY-FS5i0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ??models.vgg16_bn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWoK-iJPT_SW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ??models.vgg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU5na477UpRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ??models.vgg.make_layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqOImVSDZDYe",
        "colab_type": "code",
        "outputId": "212ef0ec-3aa0-4f66-a328-7c8b129401a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# m = models.vgg16_bn(True).features.cuda().eval()\n",
        "# blocks = [i-1 for i,o in enumerate(children(m)) if isinstance(o,nn.MaxPool2d)]\n",
        "# l = [m[i] for i in blocks[2:5]]\n",
        "# l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ReLU(inplace), ReLU(inplace), ReLU(inplace)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxUGW63OQZM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeatureLoss(nn.Module):\n",
        "  \"\"\"Feature loss required for pretraining Generator\"\"\"\n",
        "  def __init__(self, layer_wts=[20,70,10]):\n",
        "    super.__init__()\n",
        "    # Feature extractor\n",
        "    # .features gets the layers of the model with pretrained weights \n",
        "    self.m_feat = models.vgg16_bn(True).features.cuda().eval()\n",
        "    requires_grad(self.m_feat, False)\n",
        "    # Selecting the activation layers just before downsampling occurs\n",
        "    blocks = [i-1 for i,o in enumerate(children(self.m_feat)) if isinstance(o,nn.MaxPool2d)]\n",
        "    layers_ids = blocks[2:5]\n",
        "    self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
        "    # Takes the outputs of these specific layers which \n",
        "    self.hooks = hook_outputs(self.loss_features, detach=False)\n",
        "    self.wgts = layer_wgts\n",
        "    self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))]\n",
        "    self.base_loss = F.l1_loss\n",
        "  \n",
        "  def _make_features(self, x, clone=False):\n",
        "    self.m_feat(x)\n",
        "    # .clone() copies the tensor while still keeping the copy attached to the graph\n",
        "    return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
        "\n",
        "  def forward(self, input, target):\n",
        "    out_feat = self._make_features(target, clone=True) # Extract features for the target image (Colored)\n",
        "    in_feat = self._make_features(input) # Extract features for the tfmed image\n",
        "    self.feat_losses = [self.base_loss(input,target)]\n",
        "    self.feat_losses += [self.base_loss(f_in, f_out)*w\n",
        "                         for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "    \n",
        "    self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
        "    return sum(self.feat_losses)\n",
        "\n",
        "  def __del__(self): self.hooks.remove()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq0w9kW0p-Z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WassFeatureLoss(nn.Module):\n",
        "  \"\"\"Feature loss paired with wasserstein loss\"\"\"\n",
        "  def __init__(self, layer_wgts=[5,15,2], wass_wgts=[3.0,0.7,0.01]):\n",
        "    super.__init__()\n",
        "    self.m_feat = models.vgg16_bn(True).features.cuda().eval()\n",
        "    requires_grad(self.m_feat, False)\n",
        "    blocks = [i-1 for i,o in enumerate(children(self.m_feat)) if isinstance(o,nn.MaxPool2d)]\n",
        "    layers_id = blocks[2:5]\n",
        "    self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
        "    self.wgts = layer_wgts\n",
        "    self.wass_wgts = wass_wgts\n",
        "    self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))] + [f'wass_{i}' for i in range(len(layer_ids))]\n",
        "    self.base_loss = F.l1_loss\n",
        "\n",
        "  def _make_features(self, x, clone=False):\n",
        "    self.m_feat(x)\n",
        "    return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
        "\n",
        "  def _calc_2_moments(self, tensor):\n",
        "    # ?? Comeback when used\n",
        "    chans = tensor.shape[1]\n",
        "    tensor = tensor.view(1, chans, -1)\n",
        "    n = tensor.shape[2]\n",
        "    mu = tensor.mean(2)\n",
        "    # Centering the values of the tensor to later find out the covariance\n",
        "    tensor = (tensor - mu[:,:,None]).squeeze(0)\n",
        "    # Error handling\n",
        "    if n == 0: return None, None \n",
        "    # Cov with itself is variance\n",
        "    # FeatureLoss paper pg. 8. Efficient way to calculate Gram matrix\n",
        "    # might have to divide by n*chans as stated in the paper\n",
        "    cov = torch.mm(tensor, tensor.t()) / float(n)\n",
        "    return mu, cov\n",
        "\n",
        "  def _get_style_vals(self, tensor):\n",
        "    mean, cov = self._calc_2_moments(tensor)\n",
        "    if mean is None:\n",
        "      return None, None, None\n",
        "    eigvals, eigvects = torch.symeig(cov, eigenvectors=True)\n",
        "    eigroot_mat = torch.diag(torch.sqrt(eigvals.clamp(min=0)))\n",
        "    root_cov = torch.mm(torch.mm(eigvects, eigroot_mat), eigvects.t())\n",
        "    tr_cov = eigvals.clamp(min=0).sum()\n",
        "    return mean, tr_cov, root_cov\n",
        "\n",
        "\n",
        "  def forward(self, input, target):\n",
        "    out_feat = self._make_features(target, clone=True)\n",
        "    in_feat = self._make_features(input)\n",
        "    self.feat_losses = [self.base_loss(input,target)]\n",
        "    self.feat_losses += [self.base_loss(f_in, f_out)*w\n",
        "                         for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
        "    \n",
        "    # Uptil now only the feature reconstruction loss is implemented \n",
        "    # W-GAN will only have a part in the style reconstruction loss\n",
        "    # Style of the target image is extracted \n",
        "    styles = [self._get_style_vals(i) for i in out_feat]\n",
        "\n",
        "    if styles[0][0] is not None:\n",
        "      self.feat_losses += [self._single_wass_loss(f_pred, f_targ)*w\n",
        "                           for f_pred, f_targ, w in zip(in_feat, styles, self.wass_wgts)]\n",
        "\n",
        "    self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
        "    return sum(self.feat_losses)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD9Aft4vObJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "36008863-c1f2-43d2-d077-6d2f77e1ad11"
      },
      "source": [
        "torch.randn(1,2) * torch.randn(2,1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0517, -0.7658],\n",
              "        [ 0.0377, -0.5578]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NaIfXoHXXYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8291016c-d1ff-4748-da7e-1555f27b5c24"
      },
      "source": [
        "torch.randn(4,5,3).sum()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-4.1681)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO-0PH_7gtxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}